{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from skimage.io import imsave\n",
    "from multiprocessing import Pool, Process, Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(datapath='lane_marking_examples'):\n",
    "    filenames = []\n",
    "    for top, dirs, files in os.walk(datapath):\n",
    "        filenames.extend([os.path.join(top, _file) for _file in files])\n",
    "    filenames.sort()\n",
    "\n",
    "    x_paths = [x for x in filenames if not x.endswith('bin.png')]\n",
    "    y_paths = [x for x in filenames if x.endswith('bin.png')]\n",
    "    \n",
    "    return x_paths, y_paths\n",
    "    \n",
    "x_paths, y_paths = get_filenames()\n",
    "print(f'Got {x_paths.__len__()} xdata filenames and {y_paths.__len__()} ydata filenames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filepath, resize=True, pic_h=int(2710 / 4), pic_w = int(3384 / 4)):\n",
    "    if resize:\n",
    "        img = cv2.imread(filepath)\n",
    "    else:\n",
    "        img = cv2.resize(cv2.imread(y), (pic_h, pic_w), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "    return filepath, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pair(task_queue, out_queue):\n",
    "    # Height and width to resize images\n",
    "    # Defaults: 2710, 3384\n",
    "    # Coef = 4: 677, 846 [OLD]\n",
    "    # Coef ~ 4: 672, 832 [Divisible by 32]\n",
    "    \n",
    "    pic_h = 672\n",
    "    pic_w = 832\n",
    "    \n",
    "    # Start: Labels conversion dict ===========================\n",
    "    labels = {\n",
    "        (0, 0, 0):       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        (8, 35, 142):    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        (43, 173, 180):  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        (153, 102, 153): [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        (234, 168, 160): [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        (192, 0, 0):     [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        (8, 32, 128):    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        (12, 51, 204):   [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        (70, 25, 100):   [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        (14, 57, 230):   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        (75, 47, 190):   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "        (255, 255, 255): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n",
    "    labels = dict([(k, np.array(v)) for k, v in labels.items()])\n",
    "    # End:   Labels conversion dict ===========================\n",
    "    \n",
    "    while True:\n",
    "        xfilepath, yfilepath = task_queue.get()\n",
    "        \n",
    "        if xfilepath == '':\n",
    "            break\n",
    "        \n",
    "        img = cv2.resize(cv2.imread(xfilepath), (pic_w, pic_h), interpolation=cv2.INTER_NEAREST)\n",
    "        lbl = cv2.resize(cv2.imread(yfilepath), (pic_w, pic_h), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "        mask = np.zeros((pic_h, pic_w, len(labels)))\n",
    "        for rgb, categorical_lbl in labels.items():\n",
    "            mask[(lbl == rgb).all(2)] = categorical_lbl\n",
    "        \n",
    "        out_queue.put((img, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSES = 30\n",
    "LOAD_FROM = 0\n",
    "LOAD_TO = 1000\n",
    "LOADED_TOTAL = LOAD_TO - LOAD_FROM\n",
    "\n",
    "PIC_H, PIC_W = 672, 832\n",
    "LABELS_NUMBER = 12\n",
    "\n",
    "q_tasks = Queue()\n",
    "q_outs = Queue()\n",
    "\n",
    "for i in range(LOAD_FROM, LOAD_TO):\n",
    "    q_tasks.put((x_paths[i], y_paths[i]))\n",
    "for i in range(PROCESSES):\n",
    "    q_tasks.put(('', ''))\n",
    "\n",
    "# Img and masks arrays\n",
    "x_data = np.zeros((LOADED_TOTAL, PIC_H, PIC_W, 3), dtype=np.uint8)\n",
    "y_data = np.zeros((LOADED_TOTAL, PIC_H, PIC_W, 12), dtype=np.float64)\n",
    "\n",
    "processes = [Process(target=load_pair, args=(q_tasks, q_outs,)) for _ in range(PROCESSES)]\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "for i in tqdm.tqdm_notebook(range(LOADED_TOTAL)):\n",
    "    img, mask = q_outs.get()\n",
    "    x_data[i] = img\n",
    "    y_data[i] = mask\n",
    "\n",
    "print('Converting x_data...')\n",
    "x_data = x_data / 255.\n",
    "print('Converting y_data... [reshaping]')\n",
    "y_data = y_data.reshape(len(y_data), PIC_H * PIC_W, LABELS_NUMBER)\n",
    "\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "print('Goto-vo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]='PCI_BUS_ID'   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'\n",
    "\n",
    "import json\n",
    "from keras import models\n",
    "from keras.layers.core import Activation, Reshape, Permute\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "class SegnetBuilder:\n",
    "    @staticmethod\n",
    "    def build(model_name, img_h, img_w, img_layers, n_labels, kernel=3,\n",
    "              save_path='models/{}.json') -> models.Sequential:\n",
    "        encoding_layers = [\n",
    "            Conv2D(64, kernel, padding='same', input_shape=(img_w, img_h, img_layers)),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(64, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Conv2D(128, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(128, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "            ]\n",
    "\n",
    "        decoding_layers = [\n",
    "            UpSampling2D(),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(128, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Conv2D(128, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(64, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Conv2D(64, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(n_labels, (1, 1), padding='valid'),\n",
    "            BatchNormalization(),\n",
    "            ]\n",
    "\n",
    "        autoencoder = models.Sequential()\n",
    "        autoencoder.encoding_layers = encoding_layers\n",
    "\n",
    "        for l in autoencoder.encoding_layers:\n",
    "            autoencoder.add(l)\n",
    "            # print(l.input_shape, l.output_shape, l)\n",
    "\n",
    "        autoencoder.decoding_layers = decoding_layers\n",
    "        for l in autoencoder.decoding_layers:\n",
    "            autoencoder.add(l)\n",
    "\n",
    "        autoencoder.add(Reshape((n_labels, img_h * img_w)))\n",
    "        autoencoder.add(Permute((2, 1)))\n",
    "        autoencoder.add(Activation('softmax'))\n",
    "\n",
    "        with open(save_path.format(model_name), 'w') as outfile:\n",
    "            outfile.write(json.dumps(json.loads(autoencoder.to_json()), indent=2))\n",
    "\n",
    "        return autoencoder\n",
    "\n",
    "print('Goto-vo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Segnet-1000'\n",
    "segnet = SegnetBuilder.build(model_name, PIC_W, PIC_H, 3, LABELS_NUMBER)\n",
    "\n",
    "segnet.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0.0001,\n",
    "                           patience=10, verbose=1, mode='auto')\n",
    "checkpoint = ModelCheckpoint(f'models/{model_name}.hdf5',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='auto')\n",
    "\n",
    "callbacks = [early_stop, checkpoint]\n",
    "\n",
    "history = segnet.fit(x_data, y_data, batch_size=1, epochs=1, # epochs=20\n",
    "                     verbose=1, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_to_label(predictions):\n",
    "    labels = {\n",
    "        0: (0, 0, 0),\n",
    "        1: (8, 35, 142), \n",
    "        2: (43, 173, 180),\n",
    "        3: (153, 102, 153),\n",
    "        4: (234, 168, 160),\n",
    "        5: (192, 0, 0),\n",
    "        6: (8, 32, 128),\n",
    "        7: (12, 51, 204),\n",
    "        8: (70, 25, 100),\n",
    "        9: (14, 57, 230),\n",
    "        10: (75, 47, 190),\n",
    "        11: (255, 255, 255)}\n",
    "    \n",
    "    # masks = np.zeros((len(predictions), PIC_H, PIC_W, 3))\n",
    "    masks = []\n",
    "    for ind, pred in enumerate(predictions):\n",
    "        pred = pred.reshape(PIC_H, PIC_W, 12)\n",
    "        pred = np.apply_along_axis(lambda x: np.argmax(x), axis=2, arr=pred)\n",
    "        h_pred = np.zeros((PIC_H, PIC_W, 3), dtype=np.uint8)\n",
    "        for argmax, rgb in labels.items():\n",
    "            h_pred[pred == argmax] = rgb\n",
    "\n",
    "        masks.append(h_pred)\n",
    "    \n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index = 999\n",
    "print('Making predictions...')\n",
    "predictions = segnet.predict(np.expand_dims(x_data[pred_index], axis=0))\n",
    "\n",
    "print('Converting pred to human mask...')\n",
    "human_pred = predict_to_label(predictions)[0]\n",
    "print('Converting mask to human mask...')\n",
    "human_mask = predict_to_label([y_data[pred_index]])[0]\n",
    "\n",
    "print('Saving result...')\n",
    "imsave('img.png', np.concatenate((human_mask, human_pred), axis=0))\n",
    "print('Goto-vo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = 0\n",
    "falses = 0\n",
    "for h in range(PIC_H):\n",
    "    for w in range(PIC_W):\n",
    "        e = np.argmax(y_data[33].reshape(PIC_H, PIC_W, 12)[h][w]) == np.argmax(predictions.reshape(PIC_H, PIC_W, 12)[h][w])\n",
    "        if e:\n",
    "            trues += 1\n",
    "        else:\n",
    "            falses += 1\n",
    "trues / (trues + falses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
