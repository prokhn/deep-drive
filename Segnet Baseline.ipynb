{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from skimage.io import imread, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datapath='lane_marking_examples', load_from=0, load_count=-1, resize_coef=4):\n",
    "    filenames = []\n",
    "    for top, dirs, files in os.walk(datapath):\n",
    "        filenames.extend([os.path.join(top, _file) for _file in files])\n",
    "    filenames.sort()\n",
    "\n",
    "    x_paths = [x for x in filenames if not x.endswith('bin.png')]\n",
    "    y_paths = [x for x in filenames if x.endswith('bin.png')]\n",
    "\n",
    "    if load_count != -1:\n",
    "        x_paths = x_paths[load_from:load_from + load_count]\n",
    "        y_paths = y_paths[load_from:load_from + load_count]\n",
    "    \n",
    "    pic_w, pic_h, pic_ch = cv2.imread(x_paths[0]).shape\n",
    "    \n",
    "    if resize_coef != 1:\n",
    "        pic_w, pic_h = int(pic_w / resize_coef), int(pic_h / resize_coef)\n",
    "    \n",
    "    xdata = np.zeros((len(x_paths), pic_w, pic_h, pic_ch), dtype=np.uint8)\n",
    "    ydata = np.zeros((len(x_paths), pic_w, pic_h, pic_ch), dtype=np.uint8)\n",
    "\n",
    "    xdata_size = round(xdata.nbytes / 1024 / 1024 / 1024, 2)\n",
    "    ydata_size = round(ydata.nbytes / 1024 / 1024 / 1024, 2)\n",
    "    \n",
    "    print(f'XData size: {xdata_size} GB,\\nYData size: {ydata_size} GB\\nTotal: {xdata_size} GB')\n",
    "    if resize_coef == 1:\n",
    "        for ind, x in enumerate(tqdm.tqdm_notebook(x_paths)):\n",
    "            xdata[ind] = cv2.imread(x)\n",
    "\n",
    "        for ind, y in enumerate(tqdm.tqdm_notebook(y_paths)):\n",
    "            ydata[ind] = cv2.imread(y)\n",
    "    else:\n",
    "        for ind, x in enumerate(tqdm.tqdm_notebook(x_paths)):\n",
    "            xdata[ind] = cv2.resize(cv2.imread(x), (pic_h, pic_w), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        for ind, y in enumerate(tqdm.tqdm_notebook(y_paths)):\n",
    "            ydata[ind] = cv2.resize(cv2.imread(y), (pic_h, pic_w), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "    return xdata, ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata, ydata = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.concatenate((xdata[0], ydata[0]), axis=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unqs = []\n",
    "for lbl in tqdm.tqdm_notebook(ydata):\n",
    "    _u = np.unique(lbl.reshape(-1, 3), axis=0)\n",
    "    for e in _u:\n",
    "        if tuple(e) not in unqs:\n",
    "            unqs.append(tuple(e))\n",
    "            print(len(unqs), unqs)\n",
    "    # _u = set([tuple(x) for x in np.unique(lbl.reshape(-1, 3), axis=0).tolist()])\n",
    "    # unqs.update(_u)\n",
    "unqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label colors =======\n",
    "# labels = {\n",
    "#     (153, 102, 153): ['zebra', 214], # Crossing\n",
    "#     (180, 173, 43): [],  # Road side Lane\n",
    "#     (0, 0, 192): [], # Stop before crossing\n",
    "#     (142, 35, 8): [], # Go ahead arrow\n",
    "#     (160, 168, 234): [] # Go ahead and left turn arrow}\n",
    "labels = [(0, 0, 0), (8, 35, 142), (43, 173, 180), \n",
    "          (153, 102, 153), (255, 255, 255), (192, 0, 0), \n",
    "          (8, 32, 128), (12, 51, 204), (70, 25, 100), \n",
    "          (14, 57, 230), (75, 47, 190), (234, 168, 160)]\n",
    "\n",
    "# color_codes = dict([(k, [0 for i in range(12)]) for k in labels])\n",
    "# for k in color_codes.keys():\n",
    "#     color_codes[k][list(color_codes.keys()).index(k)] = 1\n",
    "\n",
    "labels = {\n",
    " (0, 0, 0): [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    " (8, 35, 142): [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    " (43, 173, 180): [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    " (153, 102, 153): [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    " (255, 255, 255): [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    " (192, 0, 0): [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    " (8, 32, 128): [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    " (12, 51, 204): [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    " (70, 25, 100): [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    " (14, 57, 230): [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    " (75, 47, 190): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    " (234, 168, 160): [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n",
    "labels = dict([(k, np.array(v)) for k, v in labels.items()])\n",
    "\n",
    "img_h, img_w = xdata[0].shape[:2]\n",
    "\n",
    "labels_converted = np.zeros((len(ydata[:1000]), img_h, img_w, len(labels)))\n",
    "for i in tqdm.tqdm_notebook(range(len(labels_converted))):\n",
    "    for rgb, categorical_lbl in labels.items():\n",
    "        # labels_converted[i, :, :, labels.index(m)] = `\n",
    "        # np.apply_along_axis(lambda x: np.all(x), axis=2, arr=ydata[i] == m)\n",
    "        labels_converted[i, (ydata[i] == rgb).all(2)] = categorical_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]='PCI_BUS_ID'   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "\n",
    "import json\n",
    "from keras import models\n",
    "from keras.layers.core import Activation, Reshape, Permute\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "class SegnetBuilder:\n",
    "    @staticmethod\n",
    "    def build(model_name, img_h, img_w, img_layers, n_labels, kernel=3,\n",
    "              save_path='models/{}.json') -> models.Sequential:\n",
    "        encoding_layers = [\n",
    "            Conv2D(64, kernel, padding='same', input_shape=(img_w, img_h, img_layers)),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(64, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Conv2D(128, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(128, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "            ]\n",
    "\n",
    "        decoding_layers = [\n",
    "            UpSampling2D(),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(512, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(256, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(128, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Conv2D(128, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(64, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Conv2D(64, (kernel, kernel), padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Conv2D(n_labels, (1, 1), padding='valid'),\n",
    "            BatchNormalization(),\n",
    "            ]\n",
    "\n",
    "        autoencoder = models.Sequential()\n",
    "        autoencoder.encoding_layers = encoding_layers\n",
    "\n",
    "        for l in autoencoder.encoding_layers:\n",
    "            autoencoder.add(l)\n",
    "            # print(l.input_shape, l.output_shape, l)\n",
    "\n",
    "        autoencoder.decoding_layers = decoding_layers\n",
    "        for l in autoencoder.decoding_layers:\n",
    "            autoencoder.add(l)\n",
    "\n",
    "        autoencoder.add(Reshape((n_labels, img_h * img_w)))\n",
    "        autoencoder.add(Permute((2, 1)))\n",
    "        autoencoder.add(Activation('softmax'))\n",
    "\n",
    "        with open(save_path.format(model_name), 'w') as outfile:\n",
    "            outfile.write(json.dumps(json.loads(autoencoder.to_json()), indent=2))\n",
    "\n",
    "        return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segnet = SegnetBuilder.build('Segnet-1000', img_h, img_w, 3, len(labels))\n",
    "\n",
    "segnet.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0.0001,\n",
    "                           patience=10, verbose=1, mode='auto')\n",
    "checkpoint = ModelCheckpoint(f'models/{self.model_name}.hdf5',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='auto')\n",
    "\n",
    "callbacks = [early_stop, checkpoint]\n",
    "\n",
    "history = autoencoder.fit(xdata[:1000], labels_converted, batch_size=16, epochs=20,\n",
    "                          verbose=1, validation_split=0.2, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
